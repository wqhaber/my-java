<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
	<property>
		<name>dfs.replication</name>
		<value>3</value>
	</property>
	<!--
        <property>
                <name>dfs.replication.min</name>
                <value>2</value>
        </property>
        <property>
                <name>dfs.namenode.fs-limits.min-block-size</name>
                <value>10</value>
        </property>
	-->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>file://${hadoop.tmp.dir}/dfs/name1,file://${hadoop.tmp.dir}/dfs/name2</value>
	</property>
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>file://${hadoop.tmp.dir}/dfs/data1,file://${hadoop.tmp.dir}/dfs/data2</value>
	</property>

	<property>
		<name>dfs.namenode.secondary.http-address</name>
		<value>s104:50090</value>
        </property>
	<property>
                <name>dfs.hosts</name>
                <value>/soft/hadoop/etc/ha/dfs.include.conf</value>
	</property>
	<property>
		<name>dfs.hosts.exclude</name>
		<value>/soft/hadoop/etc/ha/dfs.exclude.conf</value>
	</property>

<property>
	<name>dfs.nameservices</name>
	<value>mycluster</value>
</property>
<property>
	<name>dfs.ha.namenodes.mycluster</name>
	<value>nn1,nn2</value>
</property>
<property>
	<name>dfs.namenode.rpc-address.mycluster.nn1</name>
	<value>s100:8020</value>
</property>
<property>
	<name>dfs.namenode.rpc-address.mycluster.nn2</name>
	<value>s104:8020</value>
</property>
<property>
	<name>dfs.namenode.http-address.mycluster.nn1</name>
	<value>s100:50070</value>
</property>
<property>
	<name>dfs.namenode.http-address.mycluster.nn2</name>
	<value>s104:50070</value>
</property>
<property>
	<name>dfs.namenode.shared.edits.dir</name>
	<value>qjournal://s101:8485;s102:8485;s103:8485/mycluster</value>
</property>
<property>
	<name>dfs.client.failover.proxy.provider.mycluster</name>
	<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
</property>
<property>
	<name>dfs.ha.fencing.methods</name>
	<value>
		sshfence
		shell(/bin/true)
	</value>
</property>
<property>
	<name>dfs.ha.fencing.ssh.private-key-files</name>
	<value>/home/centos/.ssh/id_rsa</value>
</property>
<property>
	<name>dfs.journalnode.edits.dir</name>
	<value>/home/centos/hadoop/ha/dfs/journal</value>
</property>
	<property>
		<name>dfs.ha.automatic-failover.enabled</name>
		<value>true</value>
	</property>
</configuration>
